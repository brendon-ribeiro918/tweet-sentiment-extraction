{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "coupled-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "linear-intersection",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "temporal-closing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla     ,PROPN     ,nsubj       ,NNP       ,noun, proper singular\n",
      "is        ,AUX       ,aux         ,VBZ       ,verb, 3rd person singular present\n",
      "looking   ,VERB      ,ROOT        ,VBG       ,verb, gerund or present participle\n",
      "at        ,ADP       ,prep        ,IN        ,conjunction, subordinating or preposition\n",
      "buying    ,VERB      ,pcomp       ,VBG       ,verb, gerund or present participle\n",
      "U.S.      ,PROPN     ,compound    ,NNP       ,noun, proper singular\n",
      "startup   ,NOUN      ,dobj        ,NN        ,noun, singular or mass\n",
      "for       ,ADP       ,prep        ,IN        ,conjunction, subordinating or preposition\n",
      "$         ,SYM       ,quantmod    ,$         ,symbol, currency\n",
      "6         ,NUM       ,compound    ,CD        ,cardinal number\n",
      "million   ,NUM       ,pobj        ,CD        ,cardinal number\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'{token.text:{10}},{token.pos_:{10}},{token.dep_:{12}},{token.tag_:{10}},{spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "moral-exposure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7fe9d923f110>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7fe9e89212f0>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7fe9f847bec0>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "romantic-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "joined-opportunity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc4.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-earthquake",
   "metadata": {},
   "source": [
    "# TOKENIZATION:\n",
    "    Process of breaking up the original text in the component pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bearing-proposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n"
     ]
    }
   ],
   "source": [
    "mystring = '\"We\\'re moving to L.A.!\"'\n",
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "isolated-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "advised-disaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"         ,PUNCT     ,punct       ,``        ,opening quotation mark\n",
      "We        ,PRON      ,nsubj       ,PRP       ,pronoun, personal\n",
      "'re       ,AUX       ,aux         ,VBP       ,verb, non-3rd person singular present\n",
      "moving    ,VERB      ,ROOT        ,VBG       ,verb, gerund or present participle\n",
      "to        ,ADP       ,prep        ,IN        ,conjunction, subordinating or preposition\n",
      "L.A.      ,PROPN     ,pobj        ,NNP       ,noun, proper singular\n",
      "!         ,PUNCT     ,punct       ,.         ,punctuation mark, sentence closer\n",
      "\"         ,PUNCT     ,punct       ,''        ,closing quotation mark\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "     print(f'{token.text:{10}},{token.pos_:{10}},{token.dep_:{12}},{token.tag_:{10}},{spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "productive-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"We're here to help! Send snail-mail, email support@oursite.com or visit us at http://www.oursite.com!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "improving-communications",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We        ,PRON      ,nsubj       ,PRP       ,pronoun, personal\n",
      "'re       ,AUX       ,ROOT        ,VBP       ,verb, non-3rd person singular present\n",
      "here      ,ADV       ,advmod      ,RB        ,adverb\n",
      "to        ,PART      ,aux         ,TO        ,infinitival \"to\"\n",
      "help      ,VERB      ,advcl       ,VB        ,verb, base form\n",
      "!         ,PUNCT     ,punct       ,.         ,punctuation mark, sentence closer\n",
      "Send      ,VERB      ,ROOT        ,VB        ,verb, base form\n",
      "snail     ,NOUN      ,compound    ,NN        ,noun, singular or mass\n",
      "-         ,PUNCT     ,punct       ,HYPH      ,punctuation mark, hyphen\n",
      "mail      ,NOUN      ,dobj        ,NN        ,noun, singular or mass\n",
      ",         ,PUNCT     ,punct       ,,         ,punctuation mark, comma\n",
      "email     ,NOUN      ,conj        ,NN        ,noun, singular or mass\n",
      "support@oursite.com,X         ,nummod      ,ADD       ,email\n",
      "or        ,CCONJ     ,cc          ,CC        ,conjunction, coordinating\n",
      "visit     ,VERB      ,conj        ,VB        ,verb, base form\n",
      "us        ,PRON      ,dobj        ,PRP       ,pronoun, personal\n",
      "at        ,ADP       ,prep        ,IN        ,conjunction, subordinating or preposition\n",
      "http://www.oursite.com,X         ,pobj        ,ADD       ,email\n",
      "!         ,PUNCT     ,punct       ,.         ,punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "for t in doc2:\n",
    "    print(f'{t.text:{10}},{t.pos_:{10}},{t.dep_:{12}},{t.tag_:{10}},{spacy.explain(t.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "assisted-cleaning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc2.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-compact",
   "metadata": {},
   "source": [
    "# Named Entities\n",
    "Going a step beyond tokens, named entities add another layer of context. The language model recognizes that certain words are organizational names while others are locations, and still other combinations relate to money, dates, etc. Named entities are accessible through the ents property of a Doc object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "falling-refund",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc8 = nlp(u'Apple to build a Hong Kong factory for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lightweight-trader",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple | to | build | a | Hong | Kong | factory | for | $ | 6 | million | \n",
      "----\n",
      "Apple - ORG -Companies, agencies, institutions, etc.\n",
      "Hong Kong - GPE -Countries, cities, states\n",
      "$6 million - MONEY -Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "for token in doc8:\n",
    "    print(token.text,end=' | ')\n",
    "print('\\n----')\n",
    "for ent in doc8.ents:\n",
    "     print(ent.text+' - '+ent.label_+' -'+str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-design",
   "metadata": {},
   "source": [
    "# Built-in Visualizers\n",
    "spaCy includes a built-in visualization tool called displaCy. displaCy is able to detect whether you're working in a Jupyter notebook, and will return markup that can be rendered in a cell right away. When you export your notebook, the visualizations will be included as HTML.\n",
    "\n",
    "For more info visit https://spacy.io/usage/visualizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "premier-delaware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to build a \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    U.K.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " factory for \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "doc = nlp(u'Apple is going to build a U.K. factory for $6 million.')\n",
    "displacy.render(doc, style='ent', jupyter=True, options={'distance': 110})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bibliographic-transcription",
   "metadata": {},
   "source": [
    "# Creating Visualizations Outside of Jupyter\n",
    "If you're using another Python IDE or writing a script, you can choose to have spaCy serve up html separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accomplished-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc = nlp(u'This is a sentence.')\n",
    "#displacy.serve(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "patent-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"In ancient Rome, some neighbors live in three adjacent houses. In the center is the house of Senex, who lives there with wife Domina, son Hero, and several slaves, including head slave Hysterium and the musical's main character Pseudolus. A slave belonging to Hero, Pseudolus wishes to buy, win, or steal his freedom. One of the neighboring houses is owned by Marcus Lycus, who is a buyer and seller of beautiful women; the other belongs to the ancient Erronius, who is abroad searching for his long-lost children (stolen in infancy by pirates). One day, Senex and Domina go on a trip and leave Pseudolus in charge of Hero. Hero confides in Pseudolus that he is in love with the lovely Philia, one of the courtesans in the House of Lycus (albeit still a virgin).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "measured-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "vital-denial",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.user_data[\"title\"] = \"This is a title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pending-range",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><h2 style=\"margin: 0\">This is a title</h2>\n",
       "\n",
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">In ancient \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Rome\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", some neighbors live in \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    three\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " adjacent houses. In the center is the house of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Senex\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", who lives there with wife \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Domina\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", son \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", and several slaves, including head slave Hysterium and the musical's main character \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pseudolus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ". A slave belonging to \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pseudolus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " wishes to buy, win, or steal his freedom. \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    One\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " of the neighboring houses is owned by \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Marcus Lycus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", who is a buyer and seller of beautiful women; the other belongs to the ancient \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Erronius\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", who is abroad searching for his long-lost children (stolen in infancy by pirates). \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    One day\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Senex\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Domina\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " go on a trip and leave \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pseudolus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " in charge of \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hero\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ". Hero confides in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pseudolus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " that he is in love with the lovely \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Philia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ", one of the courtesans in \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the House of Lycus\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (albeit still a virgin).</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-definition",
   "metadata": {},
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-statistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','running','ran','runs','easily','fairly']\n",
    "for word in words:\n",
    "    print(word + '------>' + p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "p_snow = SnowballStemmer(language='english')\n",
    "for word in words:\n",
    "    print(word + '------>' + p_snow.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase = 'I am meeting him tomorrow at the meeting'\n",
    "\n",
    "for word in phrase.split():\n",
    "    print(word + '------>' + p_snow.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "natural-presence",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "In contrast to stemming, lemmatization looks beyond word reduction, and considers a language's full vocabulary to apply a morphological analysis to words. The lemma of 'was' is 'be' and the lemma of 'mice' is 'mouse'. Further, the lemma of 'meeting' might be 'meet' or 'meeting' depending on its use in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(u\"I am a runner running in a race because I love to run since I ran today\")\n",
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{10}},{token.pos_:{10}}, {token.lemma:<{22}}, {token.lemma_:{12}},  {token.tag_:{12}},{spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"I saw eighteen mice today!\")\n",
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-source",
   "metadata": {},
   "source": [
    "# Stop Words\n",
    "Words like \"a\" and \"the\" appear so frequently that they don't require tagging as thoroughly as nouns, verbs and modifiers. We call these stop words, and they can be filtered from the text to be processed. spaCy holds a built-in list of some 305 English stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gentle-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['is'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.add('btw')\n",
    "# Set the stop_word tag on the lexeme\n",
    "nlp.vocab['btw'].is_stop = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ce00b6",
   "metadata": {},
   "source": [
    "# PHRASE MATCHING AND VOCABULARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e425d1",
   "metadata": {},
   "source": [
    "Other token attributes\n",
    "Besides lemmas, there are a variety of token attributes we can use to determine matching rules:\n",
    "\n",
    "Attribute\tDescription\n",
    "`ORTH`\tThe exact verbatim text of a token\n",
    "`LOWER`\tThe lowercase form of the token text\n",
    "`LENGTH`\tThe length of the token text\n",
    "`IS_ALPHA`, `IS_ASCII`, `IS_DIGIT`\tToken text consists of alphanumeric characters, ASCII characters, digits\n",
    "`IS_LOWER`, `IS_UPPER`, `IS_TITLE`\tToken text is in lowercase, uppercase, titlecase\n",
    "`IS_PUNCT`, `IS_SPACE`, `IS_STOP`\tToken is punctuation, whitespace, stop word\n",
    "`LIKE_NUM`, `LIKE_URL`, `LIKE_EMAIL`\tToken text resembles a number, URL, email\n",
    "`POS`, `TAG`, `DEP`, `LEMMA`, `SHAPE`\tThe token's simple and extended part-of-speech tag, dependency label, lemma, shape\n",
    "`ENT_TYPE`\tThe token's entity label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f96dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59125f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb834fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SolarPower\n",
    "#Solar-Power\n",
    "#Solar Power\n",
    "pattern1 = [{'LOWER': 'solarpower'}]\n",
    "pattern2 = [{'LOWER':'solar'}, {'IS_PUNCT': True, 'OP':'*'},{'LOWER':'power'}]\n",
    "pattern3 = [{'LOWER':'solar'},{'LOWER':'power'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb0bfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('SolarPower', None,pattern1,pattern2,pattern3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dca9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'The Solar Power industry continues to grow as demand \\\n",
    "for solarpower increases. Solar-power cars are gaining popularity.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3540eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(found_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bcad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_id, start, end in found_matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
    "    span = doc[start:end]                    # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e63a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u'Solar-powered energy runs solar-powered cars.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac7a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#found_matcher = matcher(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec038b0",
   "metadata": {},
   "source": [
    "# PHRASE MATCHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6ddc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PhraseMatcher library\n",
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94900b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../TextFiles/reaganomics.txt', encoding='utf8', errors='ignore') as f:\n",
    "    doc3 = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aafca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3739ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a list of match phrases:\n",
    "phrase_list = ['voodoo economics', 'supply-side economics', 'trickle-down economics', 'free-market economics']\n",
    "\n",
    "# Next, convert each phrase to a Doc object:\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]\n",
    "\n",
    "# Pass each Doc object into matcher (note the use of the asterisk!):\n",
    "matcher.add('VoodooEconomics', None, *phrase_patterns)\n",
    "\n",
    "# Build a list of matches:\n",
    "matches = matcher(doc3)\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681053a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
    "    span = doc3[start:end]                    # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f8575c",
   "metadata": {},
   "source": [
    "# ASSESSMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d378b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here:\n",
    "with open('../TextFiles/owlcreek.txt') as f:\n",
    "      doc = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe933a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc[:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd68b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55605398",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = [sent for sent in doc.sents]\n",
    "len(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cef3969",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f664c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in sentence[2]:\n",
    "     print(f'{token.text:{15}},{token.pos_:{5}},{token.dep_:{12}},{token.lemma_:{10}},{spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495358ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Matcher library:\n",
    "\n",
    "from spacy.matcher import Matcher\n",
    "matcher = Matcher(nlp.vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b976429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = [{'LOWER':'swimming'},{'IS_SPACE': True, 'OP':'*'},{'LOWER':'vigorously'}]\n",
    "matcher.add('Swimming',None,pattern)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecec78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "found_match = matcher(doc)\n",
    "print(found_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_id, start, end in found_match:\n",
    "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
    "    span = doc[start-5:end+5]                    # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe03f05",
   "metadata": {},
   "source": [
    "# PART OF SPEECH TAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64e25d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{10}},{token.pos_:{10}}, {token.lemma:<{22}}, {token.lemma_:{12}},  {token.tag_:{12}},{spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3112196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple Doc object\n",
    "doc = nlp(u\"The quick brown fox jumped over the lazy dog's back.\")\n",
    "show_lemmas(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806b0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(u'I read books on NLP.')\n",
    "show_lemmas(doc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfe0f9a",
   "metadata": {},
   "source": [
    "# Counting POS Tags\n",
    "The Doc.count_by() method accepts a specific token attribute as its argument, and returns a frequency count of the given attribute as a dictionary object. Keys in the dictionary are the integer values of the given attribute ID, and values are the frequency. Counts of zero are not included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_counts = doc.count_by(spacy.attrs.POS)\n",
    "POS_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f37330",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.vocab[83].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030d3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(tex):\n",
    "    POS_counts = tex.count_by(spacy.attrs.POS)\n",
    "    for k,v in sorted(POS_counts.items()):\n",
    "         print(f'{k}. {tex.vocab[k].text:{5}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c67b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "count(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52934c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TAG Counts:\n",
    "def TAG(tex):\n",
    "    DEP_counts = tex.count_by(spacy.attrs.DEP)\n",
    "    for k,v in sorted(DEP_counts.items()):\n",
    "        print(f'{k}. {tex.vocab[k].text:{5}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a87ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8431c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edfda00",
   "metadata": {},
   "source": [
    "# VISUALIZING:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b943ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(tec):\n",
    "    for sent in tec.sents:\n",
    "        docx = nlp(sent.text)\n",
    "        if docx.ents:\n",
    "            displacy.render(docx, style='ent', jupyter=True)\n",
    "        else:\n",
    "             print(docx.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2eac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million. '\n",
    "         u'By contrast, Sony sold only 7 thousand Walkman music players.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e187e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4f3c0e",
   "metadata": {},
   "source": [
    "# NAMED ENTITY RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfca40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to display basic entity info:\n",
    "def show_ents(doc):\n",
    "    if doc.ents:\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))\n",
    "    else:\n",
    "        print('No named entities found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652ae900",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'May I go to Washington, DC next May to see the Washington Monument?')\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e53ec1",
   "metadata": {},
   "source": [
    "# Adding a Named Entity to a Span\n",
    "Normally we would have spaCy build a library of named entities by training it on several samples of text.\n",
    "In this case, we only want to add one value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cba9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Tesla to build a U.K. factory for $6 million')\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be89ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "# Get the hash value of the ORG entity label\n",
    "ORG = doc.vocab.strings[u'ORG']  \n",
    "\n",
    "# Create a Span for the new entity\n",
    "new_ent = Span(doc, 0, 1, label=ORG)\n",
    "\n",
    "# Add the entity to the existing Doc object\n",
    "doc.ents = list(doc.ents) + [new_ent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a33f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6b5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Our company plans to introduce a new vacuum cleaner. '\n",
    "          u'If successful, the vacuum cleaner will be our first product.')\n",
    "\n",
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ba769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "matcher = PhraseMatcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a5020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a list of match phrases:\n",
    "phrase_list = ['vacuum cleaner', 'vacuum-cleaner']\n",
    "\n",
    "# Next, convert each phrase to a Doc object:\n",
    "phrase_patterns = [nlp(text) for text in phrase_list]\n",
    "\n",
    "# Pass each Doc object into matcher (note the use of the asterisk!):\n",
    "matcher.add('vacuum', None, *phrase_patterns)\n",
    "\n",
    "# Build a list of matches:\n",
    "matches = matcher(doc)\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9a585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
    "    span = doc[start:end]                    # get the matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2db218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "PROD = doc.vocab.strings[u'PRODUCT'] \n",
    "\n",
    "# Create a Span for the new entity\n",
    "new_ent = [Span(doc, match[1], match[2], label=PROD) for match in matches]\n",
    "\n",
    "# Add the entity to the existing Doc object\n",
    "doc.ents = list(doc.ents) + new_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b36e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Originally priced at $29.50, the sweater was marked down to five dollars.')\n",
    "\n",
    "[ent for ent in doc.ents if ent.label_==\"MONEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "00300179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the displaCy library\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "920395dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    the last quarter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    nearly 20 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPods\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " for a profit of \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    $6 million\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ". By contrast, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sony\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    only 7 thousand\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " Walkman music players.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(u'Over the last quarter Apple sold nearly 20 thousand iPods for a profit of $6 million. '\n",
    "         u'By contrast, Sony sold only 7 thousand Walkman music players.')\n",
    "displacy.render(doc, style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "443d8200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Over the last quarter \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold nearly 20 thousand \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    iPods\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " for a profit of $6 million. By contrast, \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Sony\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " sold only 7 thousand Walkman music players.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options = {'ents': ['ORG', 'PRODUCT']}\n",
    "\n",
    "displacy.render(doc, style='ent', jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ac3d43",
   "metadata": {},
   "source": [
    "# SENTENCE SEGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0c10d700",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.\n",
      "This is another sentence.\n",
      "This is the last sentence.\n"
     ]
    }
   ],
   "source": [
    "# From Spacy Basics:\n",
    "doc = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)\n",
    "nlp.pipe_names\n",
    "['tagger', 'set_custom_boundaries', 'parser', 'ner']\n",
    "# Re-run the Doc object creation:\n",
    "doc4 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "​\n",
    "for sent in doc4.sents:\n",
    "    print(sent)\n",
    "\"Management is doing things right;\n",
    "leadership is doing the right things.\"\n",
    "-Peter\n",
    "Drucker\n",
    "ASSIGNMENT\n",
    "with open('../TextFiles/peterrabbit.txt') as f:\n",
    "    doc = nlp(f.read())\n",
    "doc\n",
    "doc\n",
    "The Tale of Peter Rabbit, by Beatrix Potter (1902).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d08ccf37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is the first sentence.,\n",
       " This is another sentence.,\n",
       " This is the last sentence.]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sents = [sent for sent in doc.sents]\n",
    "doc_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0ebbf3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc_sents[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9b872679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right; leadership is doing the right things.\"\n",
      "-Peter\n",
      "Drucker\n"
     ]
    }
   ],
   "source": [
    "# SPACY'S DEFAULT BEHAVIOR\n",
    "doc3 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "\n",
    "for sent in doc3.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "6dce157d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'set_custom_boundaries', 'parser', 'ner']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ADD A NEW RULE TO THE PIPELINE\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == ';':\n",
    "            doc[token.i+1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(set_custom_boundaries, before='parser')\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f13b71ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Management is doing things right;\n",
      "leadership is doing the right things.\"\n",
      "-Peter\n",
      "Drucker\n"
     ]
    }
   ],
   "source": [
    "# Re-run the Doc object creation:\n",
    "doc4 = nlp(u'\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker')\n",
    "\n",
    "for sent in doc4.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e079af73",
   "metadata": {},
   "source": [
    "# ASSIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "09af5a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../TextFiles/peterrabbit.txt') as f:\n",
    "    doc = nlp(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f0ffcf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The Tale of Peter Rabbit, by Beatrix Potter (1902).\n",
       "\n",
       "Once upon a time there were four little Rabbits, and their names\n",
       "were--\n",
       "\n",
       "          Flopsy,\n",
       "       Mopsy,\n",
       "   Cotton-tail,\n",
       "and Peter.\n",
       "\n",
       "They lived with their Mother in a sand-bank, underneath the root of a\n",
       "very big fir-tree.\n",
       "\n",
       "'Now my dears,' said old Mrs. Rabbit one morning, 'you may go into\n",
       "the fields or down the lane, but don't go into Mr. McGregor's garden:\n",
       "your Father had an accident there; he was put in a pie by Mrs.\n",
       "McGregor.'\n",
       "\n",
       "'Now run along, and don't get into mischief. I am going out.'\n",
       "\n",
       "Then old Mrs. Rabbit took a basket and her umbrella, and went through\n",
       "the wood to the baker's. She bought a loaf of brown bread and five\n",
       "currant buns.\n",
       "\n",
       "Flopsy, Mopsy, and Cottontail, who were good little bunnies, went\n",
       "down the lane to gather blackberries:\n",
       "\n",
       "But Peter, who was very naughty, ran straight away to Mr. McGregor's\n",
       "garden, and squeezed under the gate!\n",
       "\n",
       "First he ate some lettuces and some French beans; and then he ate\n",
       "some radishes;\n",
       "\n",
       "And then, feeling rather sick, he went to look for some parsley.\n",
       "\n",
       "But round the end of a cucumber frame, whom should he meet but Mr.\n",
       "McGregor!\n",
       "\n",
       "Mr. McGregor was on his hands and knees planting out young cabbages,\n",
       "but he jumped up and ran after Peter, waving a rake and calling out,\n",
       "'Stop thief!'\n",
       "\n",
       "Peter was most dreadfully frightened; he rushed all over the garden,\n",
       "for he had forgotten the way back to the gate.\n",
       "\n",
       "He lost one of his shoes among the cabbages, and the other shoe\n",
       "amongst the potatoes.\n",
       "\n",
       "After losing them, he ran on four legs and went faster, so that I\n",
       "think he might have got away altogether if he had not unfortunately\n",
       "run into a gooseberry net, and got caught by the large buttons on his\n",
       "jacket. It was a blue jacket with brass buttons, quite new.\n",
       "\n",
       "Peter gave himself up for lost, and shed big tears; but his sobs were\n",
       "overheard by some friendly sparrows, who flew to him in great\n",
       "excitement, and implored him to exert himself.\n",
       "\n",
       "Mr. McGregor came up with a sieve, which he intended to pop upon the\n",
       "top of Peter; but Peter wriggled out just in time, leaving his jacket\n",
       "behind him.\n",
       "\n",
       "And rushed into the tool-shed, and jumped into a can. It would have\n",
       "been a beautiful thing to hide in, if it had not had so much water in it.\n",
       "\n",
       "Mr. McGregor was quite sure that Peter was somewhere in the\n",
       "tool-shed, perhaps hidden underneath a flower-pot. He began to turn\n",
       "them over carefully, looking under each.\n",
       "\n",
       "Presently Peter sneezed--'Kertyschoo!' Mr. McGregor was after him in\n",
       "no time.\n",
       "\n",
       "And tried to put his foot upon Peter, who jumped out of a window,\n",
       "upsetting three plants. The window was too small for Mr. McGregor, and\n",
       "he was tired of running after Peter. He went back to his work.\n",
       "\n",
       "Peter sat down to rest; he was out of breath and trembling with\n",
       "fright, and he had not the least idea which way to go. Also he was\n",
       "very damp with sitting in that can.\n",
       "\n",
       "After a time he began to wander about, going lippity--lippity--not\n",
       "very fast, and looking all round.\n",
       "\n",
       "He found a door in a wall; but it was locked, and there was no room\n",
       "for a fat little rabbit to squeeze underneath.\n",
       "\n",
       "An old mouse was running in and out over the stone doorstep, carrying\n",
       "peas and beans to her family in the wood. Peter asked her the way to\n",
       "the gate, but she had such a large pea in her mouth that she could not\n",
       "answer. She only shook her head at him. Peter began to cry.\n",
       "\n",
       "Then he tried to find his way straight across the garden, but he\n",
       "became more and more puzzled. Presently, he came to a pond where Mr.\n",
       "McGregor filled his water-cans. A white cat was staring at some\n",
       "gold-fish, she sat very, very still, but now and then the tip of her\n",
       "tail twitched as if it were alive. Peter thought it best to go away\n",
       "without speaking to her; he had heard about cats from his cousin,\n",
       "little Benjamin Bunny.\n",
       "\n",
       "He went back towards the tool-shed, but suddenly, quite close to him,\n",
       "he heard the noise of a hoe--scr-r-ritch, scratch, scratch, scritch.\n",
       "Peter scuttered underneath the bushes. But presently, as nothing\n",
       "happened, he came out, and climbed upon a wheelbarrow and peeped over.\n",
       "The first thing he saw was Mr. McGregor hoeing onions. His back was\n",
       "turned towards Peter, and beyond him was the gate!\n",
       "\n",
       "Peter got down very quietly off the wheelbarrow; and started running\n",
       "as fast as he could go, along a straight walk behind some\n",
       "black-currant bushes.\n",
       "\n",
       "Mr. McGregor caught sight of him at the corner, but Peter did not\n",
       "care. He slipped underneath the gate, and was safe at last in the wood\n",
       "outside the garden.\n",
       "\n",
       "Mr. McGregor hung up the little jacket and the shoes for a scare-crow\n",
       "to frighten the blackbirds.\n",
       "\n",
       "Peter never stopped running or looked behind him till he got home to\n",
       "the big fir-tree.\n",
       "\n",
       "He was so tired that he flopped down upon the nice soft sand on the\n",
       "floor of the rabbit-hole and shut his eyes. His mother was busy\n",
       "cooking; she wondered what he had done with his clothes. It was the\n",
       "second little jacket and pair of shoes that Peter had lost in a\n",
       "fortnight!\n",
       "\n",
       "I am sorry to say that Peter was not very well during the evening.\n",
       "\n",
       "His mother put him to bed, and made some camomile tea; and she gave a\n",
       "dose of it to Peter!\n",
       "\n",
       "'One table-spoonful to be taken at bed-time.'\n",
       "\n",
       "But Flopsy, Mopsy, and Cotton-tail had bread and milk and\n",
       "blackberries for supper.\n",
       "\n",
       "THE END"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8abf6f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lemmas(text):\n",
    "    for token in list(text.sents)[4]:\n",
    "        print(f'{token.text:{10}},{token.pos_:{10}}, {token.lemma:<{22}}, {token.lemma_:{12}},  {token.tag_:{12}},{spacy.explain(token.tag_)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "08f35ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They      ,PRON      , 561228191312463089    , -PRON-      ,  PRP         ,pronoun, personal\n",
      "lived     ,VERB      , 13874798850131827181  , live        ,  VBD         ,verb, past tense\n",
      "with      ,ADP       , 12510949447758279278  , with        ,  IN          ,conjunction, subordinating or preposition\n",
      "their     ,PRON      , 561228191312463089    , -PRON-      ,  PRP$        ,pronoun, possessive\n",
      "Mother    ,PROPN     , 2563722269420572430   , Mother      ,  NNP         ,noun, proper singular\n",
      "in        ,ADP       , 3002984154512732771   , in          ,  IN          ,conjunction, subordinating or preposition\n",
      "a         ,DET       , 11901859001352538922  , a           ,  DT          ,determiner\n",
      "sand      ,NOUN      , 8689067151372652667   , sand        ,  NN          ,noun, singular or mass\n",
      "-         ,PUNCT     , 9153284864653046197   , -           ,  HYPH        ,punctuation mark, hyphen\n",
      "bank      ,NOUN      , 579043611916083110    , bank        ,  NN          ,noun, singular or mass\n",
      ",         ,PUNCT     , 2593208677638477497   , ,           ,  ,           ,punctuation mark, comma\n",
      "underneath,ADP       , 10541684631330628866  , underneath  ,  IN          ,conjunction, subordinating or preposition\n",
      "the       ,DET       , 7425985699627899538   , the         ,  DT          ,determiner\n",
      "root      ,NOUN      , 449                   , root        ,  NN          ,noun, singular or mass\n",
      "of        ,ADP       , 886050111519832510    , of          ,  IN          ,conjunction, subordinating or preposition\n",
      "a         ,DET       , 11901859001352538922  , a           ,  DT          ,determiner\n",
      "\n",
      "         ,SPACE     , 962983613142996970    , \n",
      "           ,  _SP         ,None\n",
      "very      ,ADV       , 9548244504980166557   , very        ,  RB          ,adverb\n",
      "big       ,ADJ       , 15511632813958231649  , big         ,  JJ          ,adjective\n",
      "fir       ,NOUN      , 6528353501724001063   , fir         ,  NN          ,noun, singular or mass\n",
      "-         ,PUNCT     , 9153284864653046197   , -           ,  HYPH        ,punctuation mark, hyphen\n",
      "tree      ,NOUN      , 5236966400857015965   , tree        ,  NN          ,noun, singular or mass\n",
      ".         ,PUNCT     , 12646065887601541794  , .           ,  .           ,punctuation mark, sentence closer\n",
      "\n",
      "\n",
      "        ,SPACE     , 908432558851201422    , \n",
      "\n",
      "          ,  _SP         ,None\n"
     ]
    }
   ],
   "source": [
    "show_lemmas(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1ab248ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide a frequency list of POS tags from the entire document\n",
    "def count(tex):\n",
    "    POS_counts = tex.count_by(spacy.attrs.POS)\n",
    "    for k,v in sorted(POS_counts.items()):\n",
    "         print(f'{k}. {tex.vocab[k].text:{5}}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7066eed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84. ADJ  : 49\n",
      "85. ADP  : 123\n",
      "86. ADV  : 66\n",
      "87. AUX  : 55\n",
      "89. CCONJ: 61\n",
      "90. DET  : 91\n",
      "92. NOUN : 172\n",
      "93. NUM  : 8\n",
      "94. PART : 29\n",
      "95. PRON : 108\n",
      "96. PROPN: 75\n",
      "97. PUNCT: 173\n",
      "98. SCONJ: 20\n",
      "100. VERB : 129\n",
      "103. SPACE: 99\n"
     ]
    }
   ],
   "source": [
    "count(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f02a75",
   "metadata": {},
   "source": [
    "# 4. CHALLENGE: What percentage of tokens are nouns?\n",
    "HINT: the attribute ID for 'NOUN' is 91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "27ce2348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1589825119236884"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100*POS_counts[92]/len(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3e69b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sent = [sent for sent in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9f16d3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "They lived with their Mother in a sand-bank, underneath the root of a\n",
       "very big fir-tree.\n"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_sent[4]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "27c48d30",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d4cdbaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"c39f104435b640ffb83826f50497f192-0\" class=\"displacy\" width=\"2250\" height=\"522.0\" direction=\"ltr\" style=\"max-width: none; height: 522.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">They</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"160\">lived</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"160\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"270\">with</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"270\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"380\">their</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"380\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"490\">Mother</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"490\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"600\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"600\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"710\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"710\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"820\">sand-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"820\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">bank,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">underneath</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1150\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1150\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1260\">root</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1260\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">of</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1480\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1480\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1590\">\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1590\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1700\">very</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1700\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1810\">big</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1810\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1920\">fir-</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1920\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2030\">tree.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2030\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"432.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2140\">\n",
       "\n",
       "</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2140\">SPACE</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-0\" stroke-width=\"2px\" d=\"M70,387.0 C70,332.0 130.0,332.0 130.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,389.0 L62,377.0 78,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-1\" stroke-width=\"2px\" d=\"M180,387.0 C180,332.0 240.0,332.0 240.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M240.0,389.0 L248.0,377.0 232.0,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-2\" stroke-width=\"2px\" d=\"M400,387.0 C400,332.0 460.0,332.0 460.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M400,389.0 L392,377.0 408,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-3\" stroke-width=\"2px\" d=\"M290,387.0 C290,277.0 465.0,277.0 465.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M465.0,389.0 L473.0,377.0 457.0,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-4\" stroke-width=\"2px\" d=\"M180,387.0 C180,167.0 585.0,167.0 585.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M585.0,389.0 L593.0,377.0 577.0,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-5\" stroke-width=\"2px\" d=\"M730,387.0 C730,277.0 905.0,277.0 905.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M730,389.0 L722,377.0 738,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-6\" stroke-width=\"2px\" d=\"M840,387.0 C840,332.0 900.0,332.0 900.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M840,389.0 L832,377.0 848,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-7\" stroke-width=\"2px\" d=\"M620,387.0 C620,222.0 910.0,222.0 910.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910.0,389.0 L918.0,377.0 902.0,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-8\" stroke-width=\"2px\" d=\"M180,387.0 C180,57.0 1035.0,57.0 1035.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1035.0,389.0 L1043.0,377.0 1027.0,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-9\" stroke-width=\"2px\" d=\"M1170,387.0 C1170,332.0 1230.0,332.0 1230.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1170,389.0 L1162,377.0 1178,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-10\" stroke-width=\"2px\" d=\"M1060,387.0 C1060,277.0 1235.0,277.0 1235.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1235.0,389.0 L1243.0,377.0 1227.0,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-11\" stroke-width=\"2px\" d=\"M1280,387.0 C1280,332.0 1340.0,332.0 1340.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1340.0,389.0 L1348.0,377.0 1332.0,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-12\" stroke-width=\"2px\" d=\"M1500,387.0 C1500,112.0 2020.0,112.0 2020.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1500,389.0 L1492,377.0 1508,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-13\" stroke-width=\"2px\" d=\"M1500,387.0 C1500,332.0 1560.0,332.0 1560.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1560.0,389.0 L1568.0,377.0 1552.0,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-14\" stroke-width=\"2px\" d=\"M1720,387.0 C1720,332.0 1780.0,332.0 1780.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1720,389.0 L1712,377.0 1728,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-15\" stroke-width=\"2px\" d=\"M1830,387.0 C1830,277.0 2005.0,277.0 2005.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1830,389.0 L1822,377.0 1838,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-16\" stroke-width=\"2px\" d=\"M1940,387.0 C1940,332.0 2000.0,332.0 2000.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1940,389.0 L1932,377.0 1948,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-17\" stroke-width=\"2px\" d=\"M180,387.0 C180,2.0 2030.0,2.0 2030.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2030.0,389.0 L2038.0,377.0 2022.0,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-c39f104435b640ffb83826f50497f192-0-18\" stroke-width=\"2px\" d=\"M2050,387.0 C2050,332.0 2110.0,332.0 2110.0,387.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-c39f104435b640ffb83826f50497f192-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\"></textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M2110.0,389.0 L2118.0,377.0 2102.0,377.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(list(doc.sents)[4], style='dep', jupyter=True, options={'distance': 110})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ecdc13",
   "metadata": {},
   "source": [
    "*6. Show the first two named entities from Beatrix Potter's *The Tale of Peter Rabbit **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ea040e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peter Rabbit - PERSON - People, including fictional\n",
      "Beatrix Potter - PERSON - People, including fictional\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents[:2]:\n",
    "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1aa6a6bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(doc.sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5d2845aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "list_of_sents = [nlp(sent.text) for sent in doc.sents]\n",
    "list_of_ners = [doc for doc in list_of_sents if doc.ents]\n",
    "len(list_of_ners)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1fd4d8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The Tale of \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Peter Rabbit\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", by \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Beatrix Potter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1902\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ").\n",
       "\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(list_of_sents[0], style='ent', jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ffdd2",
   "metadata": {},
   "source": [
    "Processing Pipeline in Spacy\n",
    "When you call nlp on a text, spaCy first tokenizes the text to produce a Doc object. The Doc is then processed in several different steps – this is also referred to as the processing pipeline.\n",
    "\n",
    "The pipeline used by the default models consists of a tagger, a parser and an entity recognizer. Each pipeline component returns the processed Doc, which is then passed on to the next component.\n",
    "\n",
    "image.png\n",
    "\n",
    "image.png\n",
    "\n",
    "Processing text\n",
    "When you call nlp on a text, spaCy will tokenize it and then call each component on the Doc, in order. It then returns the processed Doc that you can work with.\n",
    "\n",
    "Tips for efficient processing\n",
    "Process the texts as a stream using nlp.pipe and buffer them in batches, instead of one-by-one. This is usually much more efficient.\n",
    "Only apply the pipeline components you need. Getting predictions from the model that you don’t actually need adds up and becomes very inefficient at scale. To prevent this, use the disable keyword argument to disable components you don’t need\n",
    "In this example, we’re using nlp.pipe to process a (potentially very large) iterable of texts as a stream. Because we’re only accessing the named entities in doc.ents (set by the ner component), we’ll disable all other statistical components (the tagger and parser) during processing. nlp.pipe yields Doc objects, so we can iterate over them and access the named entity predictions:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "22d156a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['net income was $9.4 million compared to the prior year of 2.7$ million',\n",
    "        'revenue exceeds twelve billion dollars with a loss of $1b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ce684afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "46.6 ms ± 2.33 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "docs = nlp.pipe(texts, disable = ['tagger', 'parser'])\n",
    "\n",
    "for doc in docs:\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "39b8367c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "$9.4 million MONEY\n",
      "the prior year DATE\n",
      "2.7$ million MONEY\n",
      "\n",
      "twelve billion dollars MONEY\n",
      "1b MONEY\n",
      "\n",
      "55.3 ms ± 6.74 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "docs = nlp.pipe(texts)\n",
    "\n",
    "for doc in docs:\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c5ce95",
   "metadata": {},
   "source": [
    "Hashtags and Emoji Detection\n",
    "Social media posts, especially tweets, can be difficult to work with. They’re very short and often contain various emoji and hashtags. By only looking at the plain text, you’ll lose a lot of valuable semantic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6d3c508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a33d1237",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_emoji = [\"😀\", \"😃\", \"😂\", \"🤣\", \"😊\", \"😍\"]  # Positive emoji\n",
    "neg_emoji = [\"😞\", \"😠\", \"😩\", \"😢\", \"😭\", \"😒\"]  # Negative emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0416f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = [[{'ORTH': emoji}] for emoji in pos_emoji]\n",
    "neg = [[{'ORTH': emoji}] for emoji in neg_emoji]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ec5a46b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0ca5e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentiment(matcher, doc, i , matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    if doc.vocab.strings[match_id]== 'happy':\n",
    "        doc.sentiment += 0.1\n",
    "    elif doc.vocab.strings[match_id] == 'sad':\n",
    "        doc.sentiment -= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9ef210fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"happy\", label_sentiment, *pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "09a13bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"sad\", label_sentiment, *neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a9f9870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add('HASHTAG', None, [{'TEXT': '#'}, {'IS_ASCII': True}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6f565e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Hello guys 😀😂 #kgptalkie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dfcb0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6f668f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy \n",
      "happy \n",
      "HASHTAG \n"
     ]
    }
   ],
   "source": [
    "for match_id, starts, end in matches:\n",
    "    string_id = doc.vocab.strings[match_id]\n",
    "    span = doc[start:end]\n",
    "    print(string_id, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d416c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_course",
   "language": "python",
   "name": "nlp_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
